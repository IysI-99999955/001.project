# app/app.py

import streamlit as st
import json
import os

from src.scraper import fetch_hashtag_posts, save_posts_to_json
from src.cleaner import clean_captions
from src.sentiment import load_sentiment_model, analyze_sentiment
from src.keywords import load_keyword_model, extract_keywords, get_keyword_frequency
from src.search import search_by_keyword
from visualization.charts import plot_sentiment_distribution
from visualization.wordcloud import generate_wordcloud


DATA_DIR = "../data"
FONT_PATH = "c:/Windows/Fonts/malgun.ttf"  # í•œê¸€ ì§€ì› í°íŠ¸ (ìœˆë„ìš° ê¸°ì¤€)


def run_pipeline(hashtag, max_posts):
    st.info("ğŸ“¥ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì¤‘...")
    posts = fetch_hashtag_posts(hashtag, max_count=max_posts)
    save_path = os.path.join(DATA_DIR, f"{hashtag}_raw.json")
    save_posts_to_json(posts, save_path)

    st.success(f"âœ… ê²Œì‹œê¸€ {len(posts)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    st.info("ğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ ì¤‘...")
    posts = clean_captions(posts)

    st.info("ğŸ“Š ê°ì • ë¶„ì„ ì¤‘...")
    sentiment_model = load_sentiment_model()
    posts = analyze_sentiment(posts, sentiment_model)

    st.info("ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
    keyword_model = load_keyword_model()
    posts = extract_keywords(posts, keyword_model)

    output_path = os.path.join(DATA_DIR, f"{hashtag}_final.json")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(posts, f, ensure_ascii=False, indent=2)

    st.success("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    return posts


def main():
    st.set_page_config(page_title="ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ê¸°", layout="wide")
    st.title("ğŸ“¸ ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ê¸° (ê³µê°œ ë°ì´í„° ê¸°ë°˜)")

    hashtag = st.text_input("ë¶„ì„í•  í•´ì‹œíƒœê·¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì—¬í–‰, ootd):").strip().replace("#", "")
    max_posts = st.slider("ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜", min_value=20, max_value=500, value=100, step=10)

    if st.button("ë¶„ì„ ì‹œì‘"):
        if hashtag:
            posts = run_pipeline(hashtag, max_posts)

            st.subheader("ğŸ“ˆ ê°ì • ë¶„ì„ ê²°ê³¼")
            plot_sentiment_distribution(posts)

            st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
            generate_wordcloud(posts, font_path=FONT_PATH)

            st.subheader("ğŸ” í‚¤ì›Œë“œë¡œ ê²€ìƒ‰")
            search_term = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œ ì…ë ¥:")
            if search_term:
                results = search_by_keyword(posts, search_term)
                st.write(f"'{search_term}' í‚¤ì›Œë“œ í¬í•¨ ê²Œì‹œê¸€: {len(results)}ê°œ")
                for i, post in enumerate(results[:5], 1):
                    st.markdown(f"**{i}.** {post['cleaned_caption']}")

        else:
            st.warning("í•´ì‹œíƒœê·¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
