# src/sentiment.py

from transformers import pipeline
from typing import List, Dict
from tqdm import tqdm # tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os # os ëª¨ë“ˆ ì„í¬íŠ¸ (íŒŒì¼ ê²½ë¡œ í™•ì¸ìš©)

def load_sentiment_model(model_name: str = "snunlp/KR-FinBert"):
    """
    ê°ì • ë¶„ì„ìš© ëª¨ë¸ ë¡œë“œ
    :param model_name: Hugging Face ëª¨ë¸ ì´ë¦„
    :return: íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ê°ì²´
    """
    print(f"ğŸ”„ ê°ì • ë¶„ì„ ëª¨ë¸ '{model_name}' ë¡œë“œ ì¤‘... (ì´ ê³¼ì •ì€ ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    return pipeline("sentiment-analysis", model=model_name)


def analyze_sentiment(posts: List[Dict], model) -> List[Dict]:
    """
    cleaned_captionì„ ëŒ€ìƒìœ¼ë¡œ ê°ì • ë¶„ì„ ìˆ˜í–‰
    ëª¨ë¸ì˜ ì¶œë ¥ ë ˆì´ë¸”ì„ 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
    :param posts: ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸ (cleaned_caption í•„ë“œ í¬í•¨)
    :param model: Transformers pipeline ê°ì • ë¶„ì„ ëª¨ë¸
    :return: ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€ëœ ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸
    """
    # ëª¨ë¸ì˜ ì¶œë ¥ ë ˆì´ë¸”ì„ í•œê¸€ë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    # ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì˜ ì‹¤ì œ ì¶œë ¥ ë ˆì´ë¸”ì— ë”°ë¼ ì´ ë§¤í•‘ì„ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì˜ˆ: 'positive' -> 'ê¸ì •', 'negative' -> 'ë¶€ì •', 'neutral' -> 'ì¤‘ë¦½'
    label_map = {
        "positive": "ê¸ì •",
        "negative": "ë¶€ì •",
        "neutral": "ì¤‘ë¦½",
        "LABEL_0": "ë¶€ì •", # ëª¨ë¸ì´ LABEL_0, LABEL_1 ë“±ìœ¼ë¡œ ì¶œë ¥í•  ê²½ìš°ë¥¼ ëŒ€ë¹„ (ì˜ˆì‹œ)
        "LABEL_1": "ê¸ì •",
        # ì¶”ê°€ì ì¸ ë ˆì´ë¸”ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— ë§¤í•‘ì„ ì¶”ê°€í•˜ì„¸ìš”.
        # snunlp/KR-FinBertëŠ” ì£¼ë¡œ 'positive', 'negative'ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    }

    for post in tqdm(posts, desc="ğŸ“ ê°ì • ë¶„ì„ ì§„í–‰ ì¤‘"):
        try:
            # cleaned_captionì´ ë„ˆë¬´ ê¸¸ ê²½ìš° ëª¨ë¸ ì…ë ¥ ì œí•œì— ë§ì¶° ìë¦…ë‹ˆë‹¤.
            # ìº¡ì…˜ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš° ê±´ë„ˆëœë‹ˆë‹¤.
            if not post.get("cleaned_caption") or not isinstance(post["cleaned_caption"], str) or len(post["cleaned_caption"].strip()) == 0:
                post["sentiment"] = "ì²˜ë¦¬ë¶ˆê°€"
                post["score"] = 0.0
                continue

            result = model(post["cleaned_caption"][:512])[0]
            original_label = result["label"]
            score = round(result["score"], 4)

            # ëª¨ë¸ì˜ ì¶œë ¥ ë ˆì´ë¸”ì„ í•œê¸€ë¡œ ë§¤í•‘
            mapped_label = label_map.get(original_label.lower(), "ì¤‘ë¦½") # ê¸°ë³¸ê°’ì€ 'ì¤‘ë¦½'
            
            post["sentiment"] = mapped_label
            post["score"] = score
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ 'ERROR'ë¡œ ì²˜ë¦¬í•˜ê³  ì ìˆ˜ë¥¼ 0.0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
            # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì˜¤ë¥˜ ë¡œê¹…ì„ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            print(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} (ìº¡ì…˜: {post.get('cleaned_caption', '')[:50]}...)")
            post["sentiment"] = "ERROR"
            post["score"] = 0.0
    return posts


if __name__ == "__main__":
    import json

    # 1. ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ
    model = load_sentiment_model()

    # 2. ì…ë ¥ íŒŒì¼ ë¡œë“œ
    print("\nğŸ“‚ ì…ë ¥ íŒŒì¼ ë¡œë“œ ì¤‘...")
    try:
        # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        current_script_path = os.path.abspath(__file__)
        current_dir = os.path.dirname(current_script_path)
        project_root_dir = os.path.join(current_dir, "..", "..") # src í´ë”ì—ì„œ ë‘ ë‹¨ê³„ ìœ„ë¡œ

        input_file_path = os.path.join(project_root_dir, "data", "ì—¬í–‰_posts_cleaned.json")

        with open(input_file_path, "r", encoding="utf-8") as f:
            posts = json.load(f)
        print(f"âœ… ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ ë¡œë“œ ì™„ë£Œ.")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{input_file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        exit()
    except json.JSONDecodeError:
        print(f"âŒ ì˜¤ë¥˜: '{input_file_path}' íŒŒì¼ì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        exit()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()

    # 3. ê°ì • ë¶„ì„ ìˆ˜í–‰
    print("\nğŸ“ ê°ì • ë¶„ì„ ì‹œì‘...")
    analyzed_posts = analyze_sentiment(posts, model)
    print("âœ… ê°ì • ë¶„ì„ ì™„ë£Œ.")

    # 4. ê²°ê³¼ ì¶œë ¥ (ìƒìœ„ 5ê°œë§Œ)
    print("\nğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼ (ìƒìœ„ 5ê°œ):")
    for i, post in enumerate(analyzed_posts[:5]):
        print(f"  - ìº¡ì…˜: {post['cleaned_caption'][:50]}...")
        print(f"    ê°ì •: {post.get('sentiment', 'N/A')}, ì ìˆ˜: {post.get('score', 'N/A')}")
    
    # 5. ê°ì • ë¶„í¬ ìš”ì•½
    sentiment_counts = Counter([p.get('sentiment') for p in analyzed_posts if p.get('sentiment') != 'ERROR'])
    print("\nğŸ“ˆ ì „ì²´ ê°ì • ë¶„í¬:")
    for sentiment, count in sentiment_counts.items():
        print(f"  - {sentiment}: {count}ê°œ")

    # 6. ê²°ê³¼ ì €ì¥ (ì„ íƒ ì‚¬í•­)
    output_file_path = os.path.join(project_root_dir, "data", "ì—¬í–‰_posts_analyzed.json")
    try:
        with open(output_file_path, "w", encoding="utf-8") as f:
            json.dump(analyzed_posts, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file_path}")
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

