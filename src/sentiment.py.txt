# src/sentiment.py

from transformers import pipeline
from typing import List, Dict
from tqdm import tqdm # tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

def load_sentiment_model(model_name: str = "nlp04/korean-sentiment-classification"):
    """
    ê°ì • ë¶„ì„ìš© ëª¨ë¸ ë¡œë“œ
    :param model_name: Hugging Face ëª¨ë¸ ì´ë¦„
    :return: íŒŒì´í”„ë¼ì¸ ëª¨ë¸ ê°ì²´
    """
    # ëª¨ë¸ ë¡œë“œê°€ ì‹œì‘ë¨ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.
    # transformers pipelineì€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œ ìì²´ ì§„í–‰ë¥  í‘œì‹œë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    print(f"ğŸ”„ ê°ì • ë¶„ì„ ëª¨ë¸ '{model_name}' ë¡œë“œ ì¤‘... (ì´ ê³¼ì •ì€ ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    return pipeline("sentiment-analysis", model=model_name)


def analyze_sentiment(posts: List[Dict], model) -> List[Dict]:
    """
    cleaned_captionì„ ëŒ€ìƒìœ¼ë¡œ ê°ì • ë¶„ì„ ìˆ˜í–‰
    :param posts: ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸ (cleaned_caption í•„ë“œ í¬í•¨)
    :param model: Transformers pipeline ê°ì • ë¶„ì„ ëª¨ë¸
    :return: ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€ëœ ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸
    """
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ê²Œì‹œê¸€ ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
    # 'desc' ë§¤ê°œë³€ìˆ˜ë¡œ ì§„í–‰ë¥  ë°” ì•ì— í‘œì‹œë  ì„¤ëª…ì„ ì§€ì •í•©ë‹ˆë‹¤.
    for post in tqdm(posts, desc="ğŸ“ ê°ì • ë¶„ì„ ì§„í–‰ ì¤‘"):
        try:
            # cleaned_captionì´ ë„ˆë¬´ ê¸¸ ê²½ìš° ëª¨ë¸ ì…ë ¥ ì œí•œì— ë§ì¶° ìë¦…ë‹ˆë‹¤.
            result = model(post["cleaned_caption"][:512])[0]
            post["sentiment"] = result["label"]
            post["score"] = round(result["score"], 4)
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ 'ERROR'ë¡œ ì²˜ë¦¬í•˜ê³  ì ìˆ˜ë¥¼ 0.0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
            # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì˜¤ë¥˜ ë¡œê¹…ì„ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            post["sentiment"] = "ERROR"
            post["score"] = 0.0
    return posts


if __name__ == "__main__":
    import json

    # 1. ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ
    model = load_sentiment_model()

    # 2. ì…ë ¥ íŒŒì¼ ë¡œë“œ
    print("\nğŸ“‚ ì…ë ¥ íŒŒì¼ ë¡œë“œ ì¤‘...")
    try:
        with open("../data/ì—¬í–‰_posts_cleaned.json", "r", encoding="utf-8") as f:
            posts = json.load(f)
        print(f"âœ… ì´ {len(posts)}ê°œì˜ ê²Œì‹œê¸€ ë¡œë“œ ì™„ë£Œ.")
    except FileNotFoundError:
        print("âŒ ì˜¤ë¥˜: 'ì—¬í–‰_posts_cleaned.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        exit()
    except json.JSONDecodeError:
        print("âŒ ì˜¤ë¥˜: 'ì—¬í–‰_posts_cleaned.json' íŒŒì¼ì´ ìœ íš¨í•œ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        exit()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit()

    # 3. ê°ì • ë¶„ì„ ìˆ˜í–‰
    analyzed = analyze_sentiment(posts, model)

    # 4. ë¶„ì„ ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ ê°ì • ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")
    try:
        with open("../data/ì—¬í–‰_posts_analyzed.json", "w", encoding="utf-8") as f:
            json.dump(analyzed, f, ensure_ascii=False, indent=2)
        print("âœ¨ ê°ì • ë¶„ì„ ì™„ë£Œ. 'sentiment', 'score' í•„ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ê²°ê³¼ ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

