# src/scraper.py
import instaloader
import json
import os
import time
import random
from datetime import datetime
from typing import List, Dict, Optional

class SafeInstagramScraper:
    def __init__(self, min_delay: int = 30, max_delay: int = 60, max_retries: int = 3):
        """
        ì•ˆì „í•œ Instagram ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
        :param min_delay: ìµœì†Œ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
        :param max_delay: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
        :param max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        """
        self.min_delay = min_delay
        self.max_delay = max_delay
        self.max_retries = max_retries
        self.loader = None
        self._init_loader()
    
    def _init_loader(self):
        """Instaloader ì´ˆê¸°í™”"""
        try:
            self.loader = instaloader.Instaloader(
                download_pictures=False,
                download_videos=False,
                download_video_thumbnails=False,
                download_comments=False,
                save_metadata=False,
                quiet=True,
                # ë” ì•ˆì „í•œ ì„¤ì •
                sleep=True,  # ìë™ ëŒ€ê¸° ê¸°ëŠ¥ í™œì„±í™”
                max_connection_attempts=3
            )
            print("Instaloader ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"Instaloader ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _safe_delay(self):
        """ëœë¤ ëŒ€ê¸° ì‹œê°„ìœ¼ë¡œ ë” ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì²­ íŒ¨í„´ ìƒì„±"""
        delay = random.randint(self.min_delay, self.max_delay)
        print(f"ì•ˆì „ì„ ìœ„í•´ {delay}ì´ˆ ëŒ€ê¸° ì¤‘...")
        time.sleep(delay)

    def fetch_hashtag_posts(self, hashtag: str, max_count: int = 50) -> List[Dict]:
        """
        ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì•ˆì „í•œ í•´ì‹œíƒœê·¸ ìŠ¤í¬ë©
        """
        for attempt in range(self.max_retries):
            try:
                print(f"'{hashtag}' í•´ì‹œíƒœê·¸ ìŠ¤í¬ë© ì‹œë„ {attempt + 1}/{self.max_retries}")
                
                hashtag_obj = instaloader.Hashtag.from_name(self.loader.context, hashtag)
                posts = hashtag_obj.get_posts()
                
                results = []
                collected = 0
                
                for post in posts:
                    if collected >= max_count:
                        break
                    
                    try:
                        if not post.caption:
                            continue
                            
                        results.append({
                            "caption": post.caption,
                            "date": post.date_utc.strftime("%Y-%m-%d %H:%M:%S"),
                            "shortcode": post.shortcode,
                            "url": f"https://www.instagram.com/p/{post.shortcode}/",
                            "hashtag": hashtag,
                            "likes": post.likes if hasattr(post, 'likes') else 0,
                            "collected_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        })
                        
                        collected += 1
                        
                        # ê²Œì‹œê¸€ ìˆ˜ì§‘ ê°„ì—ë„ ì§§ì€ ëŒ€ê¸°
                        if collected % 10 == 0:
                            print(f"  {collected}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì™„ë£Œ...")
                            time.sleep(2)
                            
                    except Exception as e:
                        print(f"  ê²Œì‹œê¸€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        continue
                
                print(f"'{hashtag}' ìŠ¤í¬ë© ì„±ê³µ: {len(results)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘")
                return results
                
            except instaloader.exceptions.InstaloaderException as e:
                print(f"Instagram API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    wait_time = (attempt + 1) * 60  # ì ì§„ì  ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                    print(f"  {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                else:
                    print(f"  ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. '{hashtag}' ìŠ¤í¬ë© ì‹¤íŒ¨")
                    return []
                    
            except Exception as e:
                print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(30)
                else:
                    return []
        
        return []

    def scrape_multiple_hashtags(self, hashtags: List[str], max_count: int = 30) -> Dict[str, List[Dict]]:
        """
        ë§¤ìš° ì•ˆì „í•œ ë‹¤ì¤‘ í•´ì‹œíƒœê·¸ ìŠ¤í¬ë©
        """
        if len(hashtags) > 5:
            print("âš ï¸  í•œ ë²ˆì— 5ê°œ ì´ìƒì˜ í•´ì‹œíƒœê·¸ëŠ” ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("   IP ì°¨ë‹¨ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n)")
            if input().lower() != 'y':
                return {}
        
        all_results = {}
        
        for i, tag in enumerate(hashtags):
            print(f"\n[{i+1}/{len(hashtags)}] '{tag}' í•´ì‹œíƒœê·¸ ìŠ¤í¬ë© ì‹œì‘")
            print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: {(len(hashtags) - i) * (self.max_delay + 30) // 60}ë¶„")
            
            results = self.fetch_hashtag_posts(tag, max_count)
            all_results[tag] = results
            
            # ë§ˆì§€ë§‰ í•´ì‹œíƒœê·¸ê°€ ì•„ë‹ˆë¼ë©´ ì•ˆì „í•œ ëŒ€ê¸°
            if i < len(hashtags) - 1:
                self._safe_delay()
        
        return all_results

    def save_posts_to_json(self, posts: List[Dict], save_path: str) -> None:
        """JSON íŒŒì¼ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            with open(save_path, "w", encoding="utf-8") as f:
                json.dump(posts, f, ensure_ascii=False, indent=2)
                
            print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}")
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”’ ì•ˆì „í•œ Instagram ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    print("âš ï¸  ì£¼ì˜: Instagram ì •ì±…ì„ ì¤€ìˆ˜í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")
    print("âš ï¸  ìƒì—…ì  ì‚¬ìš© ì‹œ Instagram ì´ìš©ì•½ê´€ì„ í™•ì¸í•˜ì„¸ìš”.\n")
    
    # ë” ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”
    scraper = SafeInstagramScraper(
        min_delay=45,  # ìµœì†Œ 45ì´ˆ ëŒ€ê¸°
        max_delay=90,  # ìµœëŒ€ 90ì´ˆ ëŒ€ê¸°
        max_retries=3
    )
    
    # ê¶Œì¥: ë‹¨ì¼ í•´ì‹œíƒœê·¸ë§Œ ìŠ¤í¬ë©
    single_tag = "ì—¬í–‰"
    print(f"ë‹¨ì¼ í•´ì‹œíƒœê·¸ '{single_tag}' ìŠ¤í¬ë© (ê¶Œì¥ ë°©ì‹):")
    result = scraper.fetch_hashtag_posts(single_tag, max_count=30)
    
    if result:
        scraper.save_posts_to_json(result, f"../data/{single_tag}_posts.json")
        print(f"âœ… {len(result)}ê°œì˜ ê²Œì‹œê¸€ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ë‹¤ì¤‘ í•´ì‹œíƒœê·¸ (ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©)
    use_multiple = input("\në‹¤ì¤‘ í•´ì‹œíƒœê·¸ ìŠ¤í¬ë©ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if use_multiple.lower() == 'y':
        multiple_tags = ["ì¹´í˜", "ë§›ì§‘"]  # ìµœëŒ€ 2-3ê°œ ê¶Œì¥
        print(f"âš ï¸  ë‹¤ì¤‘ í•´ì‹œíƒœê·¸ ìŠ¤í¬ë© ì‹œì‘: {multiple_tags}")
        
        all_results = scraper.scrape_multiple_hashtags(multiple_tags, max_count=20)
        
        # ê° í•´ì‹œíƒœê·¸ë³„ ì €ì¥
        for tag, posts in all_results.items():
            if posts:
                scraper.save_posts_to_json(posts, f"../data/{tag}_posts.json")
        
        print(f"\nâœ… ë‹¤ì¤‘ í•´ì‹œíƒœê·¸ ìŠ¤í¬ë© ì™„ë£Œ")

if __name__ == "__main__":
    main()